import { CLOUD_SDK, getConfig } from '@cloudbase/weda-cloud-sdk';
import { normalizeNumber, generateMethodsFrom$w } from '../common/utils';
const DEFAULT_PATH = 'choices.0.message.content';
const contentPathMap = {
    hunyuan: 'Response.Choices.0.Message.Content',
};
function tcbApi() {
    return getConfig('endpointType') === 'tcb-api';
}
async function getAI() {
    if (tcbApi()) {
        // 不能用 wx.cloud，要用 js sdk 构造一个和 wx.cloud.extend.AI 一样的对象。 ps：大致一样，onText 那些回调先不加
        const cloudbase = await CLOUD_SDK.getCloudInstance();
        const ai = (await cloudbase?.ai());
        return {
            ...ai,
            createModel: (provider) => {
                const model = ai.createModel(provider);
                return {
                    streamText: async ({ data, timeout }) => {
                        const res = await model.streamText(data, { timeout });
                        return {
                            textStream: res.textStream,
                            eventStream: asyncFilterMap(res.dataStream, (x) => ({ value: { data: JSON.stringify(x) } })),
                        };
                    },
                    generateText: async (data) => {
                        const res = await model.generateText(data);
                        return res.rawResponses[0];
                    },
                };
            },
            bot: new Proxy({
                ...ai.bot,
                getFeedBack: ai.bot.getFeedback,
                getRecommendQuestions: async ({ data, timeout }) => {
                    const res = await ai.bot.getRecommendQuestions(data, { timeout });
                    return {
                        textStream: res.textStream,
                        eventStream: res.eventSourceStream,
                    };
                },
                sendMessage: async ({ data, timeout }) => {
                    const res = await ai.bot.sendMessage(data, { timeout });
                    return {
                        textStream: res.textStream,
                        eventStream: res.eventSourceStream,
                    };
                },
            }, {
                get(target, prop) {
                    return target[prop] || ai.bot?.[prop];
                },
            }),
        };
    }
    else {
        // 可以用 wx.cloud，但是从 cloud sdk 拿，可能会有共享环境用 wx.cloud.Cloud
        return (await CLOUD_SDK.getCloudInstance())?.extend?.AI;
    }
}
async function ensureAI() {
    const ai = await getAI();
    if (!ai)
        throw new Error(tcbApi() ? '获取 @cloudbase/js-sdk AI 模块失败' : '获取 `wx.cloud.extend.AI` 失败，微信基础库版本要求 >= 3.7.1');
    return ai;
}
export function createMpAiAPI(ctx) {
    return { ai: createAiMethods(ctx) };
}
const DEFAULT_STREAM_TIMEOUT = 60 * 3 * 1000;
export function createAiMethods(ctx) {
    const extractContentFromLLMChatResponse = (props) => {
        return ctx.utils.get(props.response, contentPathMap[props.provider] ?? DEFAULT_PATH, '');
    };
    const LLM = {
        chat: async (params, $w) => {
            const { callEventFlow, getVarValue, setVarValue } = generateMethodsFrom$w($w);
            const { provider, model, messages, stream, varPath, setStateType, callbackEventFlowId, temperature: _temperature, top_p: _top_p, timeout = DEFAULT_STREAM_TIMEOUT, } = params;
            const ai = await ensureAI();
            const llmModel = ai.createModel(provider);
            const data = { model, messages };
            const [top_p, temperature] = [_top_p, _temperature].map(normalizeNumber);
            if (top_p !== null)
                Object.assign(data, { top_p });
            if (temperature !== null)
                Object.assign(data, { temperature });
            if (stream) {
                const { textStream: _textStream, eventStream: _eventStream } = (await llmModel.streamText({
                    data,
                    timeout,
                }));
                const streamRes = {
                    textStream: _textStream,
                    eventStream: handleEventStream(_eventStream),
                };
                const ret = {
                    textStream: streamRes.textStream,
                    eventStream: streamRes.eventStream,
                };
                const setResultToVar = async () => {
                    if (varPath) {
                        let beginningStr = setStateType === 'append' ? getVarValue(varPath) ?? '' : '';
                        const [retTextStream, readTextStream] = asyncTee(streamRes.textStream, 2);
                        ret.textStream = retTextStream;
                        for await (let text of readTextStream) {
                            beginningStr += text;
                            setVarValue(varPath, beginningStr);
                        }
                    }
                };
                const callCallbackEventFlow = async () => {
                    if (callbackEventFlowId) {
                        const [retEventStream, readEventStream] = asyncTee(streamRes.eventStream, 2);
                        ret.eventStream = retEventStream;
                        for await (let event of readEventStream) {
                            callEventFlow(callbackEventFlowId, event);
                        }
                    }
                };
                await Promise.all([setResultToVar(), callCallbackEventFlow()]);
                return ret;
            }
            else {
                const generateRes = await llmModel.generateText(data);
                if (varPath) {
                    let beginningStr = setStateType === 'append' ? getVarValue(varPath) ?? '' : '';
                    beginningStr += extractContentFromLLMChatResponse({ provider, response: generateRes });
                    setVarValue(varPath, beginningStr);
                }
                return generateRes;
            }
        },
    };
    const bot = {
        getFeedback: async (params) => (await ensureAI()).bot.getFeedBack(params),
        getRecommendQuestions: async (params, $w) => {
            const { callEventFlow, getVarValue, setVarValue } = generateMethodsFrom$w($w);
            const { varPath, setStateType, callbackEventFlowId, timeout = DEFAULT_STREAM_TIMEOUT, ...restParams } = params;
            const ai = await ensureAI();
            const { textStream: _textStream, eventStream: _eventStream } = (await ai.bot.getRecommendQuestions({
                data: restParams,
                timeout,
            }));
            const streamRes = {
                textStream: _textStream,
                eventStream: handleEventStream(_eventStream),
            };
            const ret = {
                textStream: streamRes.textStream,
                eventStream: streamRes.eventStream,
            };
            const setResultToVar = async () => {
                if (varPath) {
                    let beginningStr = setStateType === 'append' ? getVarValue(varPath) ?? '' : '';
                    const [retTextStream, readTextStream] = asyncTee(streamRes.textStream, 2);
                    ret.textStream = retTextStream;
                    for await (let text of readTextStream) {
                        beginningStr += text;
                        setVarValue(varPath, beginningStr);
                    }
                }
            };
            const callCallbackEventFlow = async () => {
                if (callbackEventFlowId) {
                    const [retEventStream, readEventStream] = asyncTee(streamRes.eventStream, 2);
                    ret.eventStream = retEventStream;
                    for await (let event of readEventStream) {
                        callEventFlow(callbackEventFlowId, event);
                    }
                }
            };
            await Promise.all([setResultToVar(), callCallbackEventFlow()]);
            return ret;
        },
        sendMessage: async (params, $w) => {
            const { callEventFlow, getVarValue, setVarValue } = generateMethodsFrom$w($w);
            const { varPath, setStateType, callbackEventFlowId, timeout = DEFAULT_STREAM_TIMEOUT, ...restParams } = params;
            const ai = await ensureAI();
            const { textStream: _textStream, eventStream: _eventStream } = (await ai.bot.sendMessage({
                data: restParams,
                timeout,
            }));
            const streamRes = {
                textStream: _textStream,
                eventStream: handleEventStream(_eventStream),
            };
            const ret = {
                textStream: streamRes.textStream,
                eventStream: streamRes.eventStream,
            };
            const setResultToVar = async () => {
                if (varPath) {
                    let beginningStr = setStateType === 'append' ? getVarValue(varPath) ?? '' : '';
                    const [retTextStream, readTextStream] = asyncTee(streamRes.textStream, 2);
                    ret.textStream = retTextStream;
                    for await (let text of readTextStream) {
                        beginningStr += text;
                        setVarValue(varPath, beginningStr);
                    }
                }
            };
            const callCallbackEventFlow = async () => {
                if (callbackEventFlowId) {
                    const [retEventStream, readEventStream] = asyncTee(streamRes.eventStream, 2);
                    ret.eventStream = retEventStream;
                    for await (let event of readEventStream) {
                        callEventFlow(callbackEventFlowId, event);
                    }
                }
            };
            await Promise.all([setResultToVar(), callCallbackEventFlow()]);
            return ret;
        },
        uploadFiles: async ({ botId, fileList, }) => {
            const ai = await ensureAI();
            // js sdk/微信基础库高版本，已经有 uploadFiles 接口
            if (typeof ai?.bot?.uploadFiles === 'function') {
                return ai.bot.uploadFiles({ botId, fileList });
            }
            // 微信基础库低版本，自己实现
            const { token } = await ai.bot.tokenManager.getToken();
            return new Promise((res, rej) => {
                wx.request({
                    url: `https://${ai.bot.context.env}.api.tcloudbasegateway.com/v1/aibot/bots/${botId}/files`,
                    data: {
                        fileList,
                    },
                    header: {
                        Authorization: `Bearer ${token}`,
                    },
                    method: 'POST',
                    success: (r) => {
                        const { data } = r;
                        if (typeof data === 'object' && data && 'code' in data && data.code !== 'NORMAL') {
                            const message = `AI+ 请求出错，错误码：${data.code}，错误信息：${data.message}\n${JSON.stringify(data, null, 2)}`;
                            rej(message);
                            console.error(message);
                        }
                        else {
                            res(data);
                        }
                    },
                    fail(e) {
                        rej(e);
                    },
                });
            });
        },
        createConversation: async (props) => {
            const ai = await ensureAI();
            // js sdk/微信基础库已经有 createConversation 接口
            if (typeof ai?.bot?.createConversation === 'function') {
                return ai.bot.createConversation(props);
            }
            // 低版本有 token manager
            if (ai?.bot?.tokenManager) {
                // 微信基础库低版本，自己实现
                return aiReqWithTokenManager({ ai, path: `bots/${props.botId}/conversation`, data: props, method: 'POST' });
            }
            // 高版本去掉 token manager，提供 request
            if (typeof ai?.request === 'function') {
                return aiReqWithAiRequest({ ai, path: `bots/${props.botId}/conversation`, data: props, method: 'POST' });
            }
            throw new Error('`createConversation` not supported');
        },
        getConversation: async (props) => {
            const ai = await ensureAI();
            // js sdk/微信基础库已经有接口
            if (typeof ai?.bot?.getConversation === 'function') {
                return ai.bot.getConversation(props);
            }
            const { pageSize = 10, pageNumber = 1, ...rest } = props;
            if (pageNumber < 1)
                throw new Error('pageNumber must be greater than 0');
            const offset = pageSize * (pageNumber - 1);
            const limit = pageSize;
            const queryObj = {
                ...rest,
                offset,
                limit,
            };
            const queryStr = objectToParam(queryObj);
            // 低版本有 token manager
            if (ai?.bot?.tokenManager) {
                // 微信基础库低版本，自己实现
                return aiReqWithTokenManager({ ai, path: `bots/${props.botId}/conversation`, data: queryObj, method: 'GET' });
            }
            // 高版本去掉 token manager，提供 request
            if (typeof ai?.request === 'function') {
                return aiReqWithAiRequest({
                    ai,
                    path: `bots/${props.botId}/conversation/?${queryStr}`,
                    data: queryObj,
                    method: 'GET',
                });
            }
            throw new Error('`getConversation` not supported');
        },
        deleteConversation: async (props) => {
            const ai = await ensureAI();
            // js sdk/微信基础库已经有 deleteConversation 接口
            if (typeof ai?.bot?.deleteConversation === 'function') {
                return ai.bot.deleteConversation(props);
            }
            // 低版本有 token manager
            if (ai?.bot?.tokenManager) {
                // 微信基础库低版本，自己实现
                return aiReqWithTokenManager({
                    ai,
                    path: `bots/${props.botId}/conversation/${props.conversationId}`,
                    data: props,
                    method: 'DELETE',
                });
            }
            // 高版本去掉 token manager，提供 request
            if (typeof ai?.request === 'function') {
                return aiReqWithAiRequest({
                    ai,
                    path: `bots/${props.botId}/conversation/${props.conversationId}`,
                    data: props,
                    method: 'DELETE',
                });
            }
            throw new Error('`deleteConversation` not supported');
        },
        speechToText: async (props) => {
            const ai = await ensureAI();
            // js sdk/微信基础库已经有 speechToText 接口
            if (typeof ai?.bot?.speechToText === 'function') {
                return ai.bot.speechToText(props);
            }
            // 低版本有 token manager
            if (ai?.bot?.tokenManager) {
                // 微信基础库低版本，自己实现
                return aiReqWithTokenManager({ ai, path: `bots/${props.botId}/speech-to-text`, data: props, method: 'POST' });
            }
            // 高版本去掉 token manager，提供 request
            if (typeof ai?.request === 'function') {
                return aiReqWithAiRequest({ ai, path: `bots/${props.botId}/speech-to-text`, data: props, method: 'POST' });
            }
            throw new Error('`speechToText` not supported');
        },
        textToSpeech: async (props) => {
            const ai = await ensureAI();
            // js sdk/微信基础库已经有接口
            if (typeof ai?.bot?.textToSpeech === 'function') {
                return ai.bot.textToSpeech(props);
            }
            // 低版本有 token manager
            if (ai?.bot?.tokenManager) {
                // 微信基础库低版本，自己实现
                return aiReqWithTokenManager({ ai, path: `bots/${props.botId}/text-to-speech`, data: props, method: 'POST' });
            }
            // 高版本去掉 token manager，提供 request
            if (typeof ai?.request === 'function') {
                return aiReqWithAiRequest({ ai, path: `bots/${props.botId}/text-to-speech`, data: props, method: 'POST' });
            }
            throw new Error('`textToSpeech` not supported');
        },
        getTextToSpeechResult: async (props) => {
            const ai = await ensureAI();
            // js sdk/微信基础库已经有 getTextToSpeechResult 接口
            if (typeof ai?.bot?.getTextToSpeechResult === 'function') {
                return ai.bot.getTextToSpeechResult(props);
            }
            // 低版本有 token manager
            if (ai?.bot?.tokenManager) {
                // 微信基础库低版本，自己实现
                return aiReqWithTokenManager({
                    ai,
                    path: `bots/${props.botId}/text-to-speech`,
                    data: props,
                    method: 'GET',
                });
            }
            // 高版本去掉 token manager，提供 request
            if (typeof ai?.request === 'function') {
                return aiReqWithAiRequest({
                    ai,
                    path: `bots/${props.botId}/text-to-speech`,
                    data: props,
                    method: 'GET',
                });
            }
            throw new Error('`getTextToSpeechResult` not supported');
        },
    };
    ['list', 'get', 'getChatRecords', 'sendFeedback'].forEach((methodName) => {
        bot[methodName] = async (params) => {
            return (await ensureAI()).bot[methodName](params);
        };
    });
    const ai = {
        LLM,
        bot,
    };
    return ai;
}
function handleEventStream(stream) {
    return asyncFilterMap(stream, (val) => {
        if (!val)
            return { keep: false };
        const eventDataStr = val.data;
        if (typeof eventDataStr !== 'string')
            return { keep: false };
        try {
            const parsedEventData = JSON.parse(eventDataStr);
            return {
                value: parsedEventData,
            };
        }
        catch (e) {
            if (eventDataStr === '[DONE]') {
                return {
                    done: true,
                };
            }
            console.warn(e);
            return {
                keep: false,
            };
        }
    });
}
function asyncFilterMap(asyncIterable, filterMapFn) {
    const iterator = asyncIterable[Symbol.asyncIterator](); // The original async iterator
    return {
        [Symbol.asyncIterator]() {
            return this;
        },
        async next() {
            while (true) {
                const originalIteratorResult = await iterator.next();
                if (originalIteratorResult.done) {
                    return { done: true }; // done 为 true 时就不会消费 value 了
                }
                const newIteratorResult = filterMapFn(originalIteratorResult.value);
                if (newIteratorResult.done === true) {
                    return { done: true };
                }
                if (newIteratorResult.keep === false) {
                    continue;
                }
                else {
                    return {
                        done: false,
                        value: newIteratorResult.value,
                    };
                }
            }
        },
    };
}
function asyncTee(asyncIterable, branches = 2) {
    const iterator = asyncIterable[Symbol.asyncIterator](); // The original async iterator
    const buffers = Array.from({ length: branches }, () => []); // Buffers for each branch
    let pumpPromise = null;
    async function pump() {
        if (pumpPromise !== null)
            return pumpPromise; // Avoid concurrent pumps
        pumpPromise = new Promise((res, rej) => {
            iterator
                .next()
                .then((nextRes) => {
                buffers.forEach((buffer) => buffer.push(nextRes)); // Push the result to all buffers
                if (nextRes.done) {
                    buffers.forEach((buffer) => buffer.push(null)); // Indicate completion in all buffers
                }
                res(null);
                pumpPromise = null;
            })
                .catch((e) => rej(e));
        });
    }
    // Creates an async iterator for each branch
    function makeBranch(i) {
        return {
            [Symbol.asyncIterator]() {
                return this;
            },
            async next() {
                while (buffers[i].length === 0) {
                    await pump(); // Fetch more data if the buffer is empty
                }
                const result = buffers[i].shift();
                if (result === null) {
                    return { done: true }; // Iteration is complete
                }
                return result;
            },
        };
    }
    // Return an array of async iterators for each branch
    return buffers.map((_, i) => makeBranch(i));
}
function objectToParam(obj) {
    return Object.entries(obj)
        .map(([key, value]) => `${key}=${value}`)
        .join('&');
}
async function aiReqWithTokenManager({ ai, path, data, method }) {
    const { token } = await ai.bot.tokenManager.getToken();
    return new Promise((res, rej) => {
        wx.request({
            url: `https://${ai.bot.context.env}.api.tcloudbasegateway.com/v1/aibot/${path}`,
            data,
            header: {
                Authorization: `Bearer ${token}`,
            },
            method,
            success: (r) => {
                const { data } = r;
                if (typeof data === 'object' && data && 'code' in data && data.code !== 'NORMAL') {
                    const message = `AI+ 请求出错，错误码：${data.code}，错误信息：${data.message}\n${JSON.stringify(data, null, 2)}`;
                    rej(message);
                    console.error(message);
                }
                else {
                    res(data);
                }
            },
            fail(e) {
                rej(e);
            },
        });
    });
}
async function aiReqWithAiRequest({ ai, path, data, method }) {
    return new Promise((res, rej) => {
        ai.request({
            path,
            data,
            method,
            success: (r) => {
                const { data } = r;
                if (typeof data === 'object' && data && 'code' in data && data.code !== 'NORMAL') {
                    const message = `AI+ 请求出错，错误码：${data.code}，错误信息：${data.message}\n${JSON.stringify(data, null, 2)}`;
                    rej(message);
                    console.error(message);
                }
                else {
                    res(data);
                }
            },
            fail(e) {
                rej(e);
            },
        });
    });
}
